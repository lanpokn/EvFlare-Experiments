# 主实验框架 - 项目记忆 (已更新)

## 项目概述
**事件流去炫光结果的定量评估框架**，专门用于评估**已经处理完成**的去炫光结果与真值数据的对比。

**重要澄清**：此框架 **不执行** 去炫光处理，仅负责评估外部方法的处理结果。

## 已完成的框架结构

### 核心模块
1. **data_loader.py** - 事件数据加载抽象层（支持多种格式）
2. **metrics.py** - 评估度量计算（用户提供的 Chamfer Distance 和 Gaussian Distance）
3. **methods.py** - 方法结果加载器（**已简化**，移除了处理逻辑）
4. **evaluator.py** - 实验流程协调器（**已更新**，直接比较结果）
5. **run_main_experiment.py** - 主执行脚本（**已重构**）
6. **__init__.py** - 包初始化文件
7. **requirements.txt** - 依赖列表
8. **README.md** - 详细文档（已更新）

### 设计理念 (已调整)
- **格式无关**：不假设特定目录结构，通过显式文件路径工作
- **结果导向**：评估预处理的结果文件，而非执行处理
- **方法无关**：可以评估任何外部方法的输出结果
- **度量全面**：支持多种评估指标，易于扩展
- **结果导出**：支持 CSV 导出和 pandas DataFrame

## 当前实现状态

### ✅ 已完成
- **重构完成**：移除了不必要的去炫光处理代码
- 抽象接口设计完整
- 评估流程框架搭建完毕
- 用户提供的度量函数已集成
- `MethodResult` 类用于加载预处理结果
- 结果收集和导出功能
- 错误处理和失败分析

### 🚧 需要具体实现
1. **AEDAT4 文件读取**
   - 位置：`data_loader.py` Aedat4DataSource._load_data()
   - 需要：dv-processing 库集成或自定义读取代码
   
2. **H5 文件读取** 
   - 位置：`data_loader.py` H5DataSource._load_data()
   - 需要：基于实际 H5 文件结构的读取实现

### ❌ 已移除
- ~~主模型推理管道~~ (不需要，处理在外部完成)
- ~~基线方法实现~~ (不需要，只评估结果)
- ~~所有处理相关的代码~~ (框架只负责评估)

### 💡 关键设计决策
- 所有事件数据标准化为 NumPy 结构化数组：`[('t', '<f8'), ('x', '<u2'), ('y', '<u2'), ('p', 'i1')]`
- 度量计算使用用户提供的归一化和距离计算方法
- 支持中间结果保存用于调试和分析
- 完整的错误处理和失败追踪机制
- **核心理念**：框架专注于评估，不涉及处理逻辑

## 使用流程 (已更新)
1. 在外部完成去炫光处理，得到结果文件
2. 更新 `run_main_experiment.py` 中的方法结果路径和真值数据路径
3. 补充所需文件格式的读取代码（如果使用 AEDAT4 或 H5）
4. 运行评估：`python run_main_experiment.py --output results/`

## 数据格式要求 (已更新)
- **方法结果**：外部处理得到的去炫光结果文件
- **真值数据**：仅包含背景的干净事件流
- **输出格式**：评估度量和比较报告

## 框架优势
- **清晰职责**：专注评估，不负责处理
- **灵活性**：可评估任何方法的结果
- **可扩展**：易于添加新的度量标准
- **格式支持**：支持多种事件数据格式

这个重构后的框架更符合实际需求，提供了一个专业的评估工具，可以公平比较不同去炫光方法的效果。