#!/usr/bin/env python3
"""
H5äº‹ä»¶æ•°æ®æ‰¹é‡é‡å»ºè„šæœ¬
æ‰¹é‡å¤„ç†events_h5ç›®å½•ä¸­çš„æ‰€æœ‰H5æ–‡ä»¶ï¼Œä¸ºæ¯ä¸ªç”Ÿæˆå¯¹åº”çš„é‡å»ºå›¾åƒ

åŠŸèƒ½ï¼š
1. æ‰«æevents_h5ç›®å½•ä¸­çš„æ‰€æœ‰H5æ–‡ä»¶ï¼ˆé™¤backupæ–‡ä»¶ï¼‰
2. å¯¹æ¯ä¸ªH5æ–‡ä»¶è¿›è¡ŒH5â†’EVREALæ ¼å¼è½¬æ¢  
3. è°ƒç”¨EVREALç”Ÿæˆé‡å»ºå›¾åƒ
4. ç¡®ä¿æ—¶é—´æˆ³å¯¹é½å’Œ200:200å®Œç¾Žå¯¹åº”
5. æ ¹æ®H5æ–‡ä»¶ååˆ›å»ºç‹¬ç«‹çš„é‡å»ºè¾“å‡ºç›®å½•

Author: Claude Code Assistant  
Date: 2025-09-24
"""

import os
import sys
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import numpy as np
import h5py
import json

# å¯¼å…¥çŽ°æœ‰æ¨¡å—
sys.path.append('.')
try:
    from modules.format_converter import EVREALToH5Converter, ConversionConfig
    from modules.evreal_integration import EVREALIntegrationConfig, EVREALIntegration  
    from pipeline_architecture import DataFormat, FormatConverter
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)

class H5BatchReconstructor:
    """H5æ‰¹é‡é‡å»ºå™¨"""
    
    def __init__(self, h5_dir: Path, dataset_dir: Path = Path("datasets/lego")):
        self.h5_dir = Path(h5_dir)
        self.dataset_dir = Path(dataset_dir) 
        self.temp_dir = Path("temp/batch_reconstruction")
        
        # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
    def scan_h5_files(self) -> List[Path]:
        """æ‰«æH5ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰éœ€è¦å¤„ç†çš„H5æ–‡ä»¶"""
        if not self.h5_dir.exists():
            print(f"é”™è¯¯: H5ç›®å½•ä¸å­˜åœ¨ {self.h5_dir}")
            return []
            
        h5_files = []
        for h5_file in self.h5_dir.glob("*.h5"):
            # è·³è¿‡backupæ–‡ä»¶
            if "backup" in h5_file.name.lower() or "wrong" in h5_file.name.lower():
                print(f"è·³è¿‡backupæ–‡ä»¶: {h5_file.name}")
                continue
            h5_files.append(h5_file)
            
        print(f"æ‰¾åˆ° {len(h5_files)} ä¸ªH5æ–‡ä»¶éœ€è¦å¤„ç†:")
        for f in h5_files:
            print(f"  - {f.name}")
            
        return h5_files
    
    def load_h5_events(self, h5_file: Path) -> Optional[DataFormat.H5Events]:
        """åŠ è½½H5äº‹ä»¶æ–‡ä»¶"""
        try:
            with h5py.File(h5_file, 'r') as f:
                events_t = f['events/t'][:]  # æ—¶é—´æˆ³ï¼ˆå¾®ç§’ï¼‰
                events_x = f['events/x'][:]  # xåæ ‡
                events_y = f['events/y'][:]  # yåæ ‡  
                events_p = f['events/p'][:]  # æžæ€§
                
                # è¯»å–å…ƒæ•°æ®
                metadata = dict(f['events'].attrs)
                
            print(f"ä»Ž {h5_file.name} åŠ è½½ {len(events_t):,} ä¸ªäº‹ä»¶")
            print(f"  æ—¶é—´èŒƒå›´: {events_t.min():.0f} - {events_t.max():.0f} Î¼s")
            print(f"  ç©ºé—´èŒƒå›´: x[{events_x.min():.0f}, {events_x.max():.0f}] y[{events_y.min():.0f}, {events_y.max():.0f}]")
            
            return DataFormat.H5Events(
                events_t=events_t,
                events_x=events_x, 
                events_y=events_y,
                events_p=events_p,
                h5_file=h5_file,
                metadata=metadata
            )
            
        except Exception as e:
            print(f"åŠ è½½H5æ–‡ä»¶å¤±è´¥ {h5_file}: {e}")
            return None
    
    def h5_to_evreal_format(self, h5_events: DataFormat.H5Events, output_dir: Path) -> bool:
        """H5æ ¼å¼è½¬EVREALæ ¼å¼ - å¤ç”¨ä¸€é”®å¼çš„æˆåŠŸé…ç½®"""
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            sequence_dir = output_dir / "sequence"
            sequence_dir.mkdir(parents=True, exist_ok=True)
            
            # è½¬æ¢äº‹ä»¶æ•°æ®æ ¼å¼
            events_ts = h5_events.events_t / 1e6  # å¾®ç§’ â†’ ç§’
            events_xy = np.column_stack([h5_events.events_x, h5_events.events_y])
            events_p = h5_events.events_p
            
            # ðŸŽ¯ å…³é”®ï¼šå¤ç”¨ä¸€é”®å¼æˆåŠŸçš„EVREALé…ç½®
            reference_evreal_dir = self.dataset_dir / "events_evreal" / "sequence"
            if not reference_evreal_dir.exists():
                print(f"é”™è¯¯ï¼šå‚è€ƒEVREALç›®å½•ä¸å­˜åœ¨ {reference_evreal_dir}")
                return False
            
            print(f"å¤ç”¨ä¸€é”®å¼EVREALé…ç½®: {reference_evreal_dir}")
            
            # 1. å¤åˆ¶æ‰€æœ‰éžäº‹ä»¶æ–‡ä»¶ï¼ˆå›¾åƒã€æ—¶é—´æˆ³ã€é…ç½®ç­‰ï¼‰
            for file_path in reference_evreal_dir.glob("*"):
                if file_path.name not in ["events_ts.npy", "events_xy.npy", "events_p.npy"]:
                    if file_path.is_dir():
                        # å¤åˆ¶ç›®å½•ï¼ˆå¦‚imagesç›®å½•ï¼‰
                        target_dir = sequence_dir / file_path.name
                        if target_dir.exists():
                            shutil.rmtree(target_dir)
                        shutil.copytree(file_path, target_dir)
                        print(f"  å¤åˆ¶ç›®å½•: {file_path.name}")
                    else:
                        # å¤åˆ¶æ–‡ä»¶
                        shutil.copy2(file_path, sequence_dir / file_path.name)
                        print(f"  å¤åˆ¶æ–‡ä»¶: {file_path.name}")
            
            # 2. ä¿å­˜æ–°çš„äº‹ä»¶æ•°æ®ï¼ˆåªæ›¿æ¢äº‹ä»¶ç›¸å…³æ–‡ä»¶ï¼‰
            np.save(sequence_dir / "events_ts.npy", events_ts)
            np.save(sequence_dir / "events_xy.npy", events_xy)
            np.save(sequence_dir / "events_p.npy", events_p)
            
            # ä¹Ÿä¿å­˜åˆ°ä¸»ç›®å½•ï¼ˆEVREALæ ‡å‡†æ ¼å¼ï¼‰
            np.save(output_dir / "events_ts.npy", events_ts)
            np.save(output_dir / "events_xy.npy", events_xy) 
            np.save(output_dir / "events_p.npy", events_p)
            
            # 3. æ›´æ–°å…ƒæ•°æ®ä¸­çš„äº‹ä»¶ä¿¡æ¯
            reference_metadata_file = reference_evreal_dir / "metadata.json"
            if reference_metadata_file.exists():
                with open(reference_metadata_file, 'r') as f:
                    metadata = json.load(f)
                
                # åªæ›´æ–°äº‹ä»¶ç›¸å…³å­—æ®µ
                metadata.update({
                    "num_events": len(events_ts),
                    "time_range_s": (float(events_ts.min()), float(events_ts.max())),
                    "spatial_range": {
                        "x_range": (int(events_xy[:, 0].min()), int(events_xy[:, 0].max())),
                        "y_range": (int(events_xy[:, 1].min()), int(events_xy[:, 1].max()))
                    },
                    "source_h5": str(h5_events.h5_file),
                    "conversion_timestamp": str(np.datetime64('now'))
                })
                
                # ä¿å­˜æ›´æ–°åŽçš„å…ƒæ•°æ®
                with open(sequence_dir / "metadata.json", 'w') as f:
                    json.dump(metadata, f, indent=2)
                with open(output_dir / "metadata.json", 'w') as f:
                    json.dump(metadata, f, indent=2)
                
            print(f"âœ… H5â†’EVREALè½¬æ¢å®Œæˆ: {output_dir}")
            print(f"  âœ… äº‹ä»¶æ•°æ®: events_ts.npy {events_ts.shape}, events_xy.npy {events_xy.shape}, events_p.npy {events_p.shape}")
            print(f"  âœ… å¤ç”¨ä¸€é”®å¼é…ç½®: å›¾åƒã€æ—¶é—´æˆ³ã€é…ç½®æ–‡ä»¶ç­‰")
            
            return True
            
        except Exception as e:
            print(f"H5â†’EVREALè½¬æ¢å¤±è´¥: {e}")
            return False
    
    def generate_reconstruction_name(self, h5_file: Path) -> str:
        """æ ¹æ®H5æ–‡ä»¶åç”Ÿæˆé‡å»ºç›®å½•å"""
        # åŽ»æŽ‰.h5åŽç¼€ï¼Œæ·»åŠ reconstructionå‰ç¼€
        base_name = h5_file.stem  # æ–‡ä»¶åä¸å«åŽç¼€
        return f"reconstruction_{base_name}"
    
    def run_evreal_reconstruction(self, evreal_dir: Path, output_dir: Path, h5_name: str) -> bool:
        """è°ƒç”¨EVREALè¿›è¡Œé‡å»º - å‚è€ƒä¸€é”®å¼çš„æˆåŠŸåšæ³•"""
        try:
            # EVREALè·¯å¾„å’Œé…ç½®ï¼ˆä¸Žä¸€é”®å¼å®Œå…¨ä¸€è‡´ï¼‰
            evreal_path = Path("/mnt/e/2025/event_flick_flare/EVREAL-main/EVREAL-main")
            if not evreal_path.exists():
                print(f"é”™è¯¯: EVREALè·¯å¾„ä¸å­˜åœ¨ {evreal_path}")
                return False
            
            # æ£€æŸ¥eval.pyæ˜¯å¦å­˜åœ¨
            eval_script = evreal_path / "eval.py"
            if not eval_script.exists():
                print(f"é”™è¯¯: eval.pyä¸å­˜åœ¨ {eval_script}")
                return False
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # æˆåŠŸçš„é‡å»ºæ–¹æ³•ï¼ˆä¸Žä¸€é”®å¼é¡¹ç›®è®°å¿†ä¸€è‡´ï¼‰
            methods = ["E2VID", "FireNet", "SPADE-E2VID", "SSL-E2VID"]
            
            # é¦–å…ˆéœ€è¦åˆ›å»ºEVREALæ•°æ®é›†é…ç½®
            dataset_name = f"batch_{h5_name}"
            self.create_evreal_dataset_config(evreal_dir, dataset_name, evreal_path)
            
            success_count = 0
            for method in methods:
                print(f"  è¿è¡Œ {method} é‡å»º...")
                
                # EVREALå‘½ä»¤ï¼ˆä¸Žä¸€é”®å¼å®Œå…¨ä¸€è‡´ï¼‰
                cmd = [
                    "python", "eval.py",
                    "-m", method,
                    "-c", "std",
                    "-d", dataset_name,
                    "-qm", "mse", "ssim", "lpips"
                ]
                
                # æ¿€æ´»Umain2çŽ¯å¢ƒå¹¶è¿è¡ŒEVREALï¼ˆä¸Žä¸€é”®å¼å®Œå…¨ä¸€è‡´ï¼‰
                env_cmd = f"source ~/miniconda3/etc/profile.d/conda.sh && conda activate Umain2 && {' '.join(cmd)}"
                
                try:
                    result = subprocess.run(
                        ["bash", "-c", env_cmd],
                        cwd=evreal_path,
                        capture_output=True,
                        text=True,
                        timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶ï¼ˆä¸Žä¸€é”®å¼ä¸€è‡´ï¼‰
                    )
                    
                    if result.returncode == 0:
                        print(f"    âœ… {method}: EVREALå‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
                        success_count += 1
                    else:
                        print(f"    âŒ {method}: é‡å»ºå¤±è´¥ (è¿”å›žç : {result.returncode})")
                        if result.stderr:
                            print(f"       stderr: {result.stderr}")
                        if result.stdout:
                            print(f"       stdout: {result.stdout}")
                        
                except subprocess.TimeoutExpired:
                    print(f"    âŒ {method}: é‡å»ºè¶…æ—¶")
                except Exception as e:
                    print(f"    âŒ {method}: {e}")
            
            # å¤åˆ¶é‡å»ºç»“æžœåˆ°æˆ‘ä»¬çš„è¾“å‡ºç›®å½•
            if success_count > 0:
                self.copy_evreal_results(evreal_path, output_dir, dataset_name, methods)
            
            print(f"é‡å»ºå®Œæˆ: {success_count}/{len(methods)} æ–¹æ³•æˆåŠŸ")
            return success_count > 0
            
        except Exception as e:
            print(f"EVREALé‡å»ºè°ƒç”¨å¤±è´¥: {e}")
            return False
    
    def create_evreal_dataset_config(self, evreal_dir: Path, dataset_name: str, evreal_path: Path):
        """åˆ›å»ºEVREALæ•°æ®é›†é…ç½® - å¤ç”¨ä¸€é”®å¼çš„æˆåŠŸé…ç½®"""
        try:
            # æŸ¥æ‰¾ä¸€é”®å¼æˆåŠŸçš„æ•°æ®é›†é…ç½® - ä¿®æ­£è·¯å¾„
            config_dir = evreal_path / "config" / "dataset"  # ä¿®æ­£ï¼šå®žé™…è·¯å¾„
            config_dir.mkdir(parents=True, exist_ok=True)
            reference_config_file = config_dir / "lego.json"
            
            if not reference_config_file.exists():
                print(f"è­¦å‘Šï¼šå‚è€ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ {reference_config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                # ä½¿ç”¨é»˜è®¤é…ç½®
                config_data = {
                    "path": str(evreal_dir / "sequence"),
                    "load_name": dataset_name,
                    "voxel_method": "between_frames",
                    "num_bins": 5,
                    "clip_dist": 3,
                    "sensor": {
                        "name": "DVS346",
                        "resolution": [480, 640]  # H x W
                    }
                }
            else:
                # å¤ç”¨ä¸€é”®å¼çš„æˆåŠŸé…ç½®ï¼Œåªä¿®æ”¹è·¯å¾„å’Œåç§°
                with open(reference_config_file, 'r') as f:
                    config_data = json.load(f)
                
                # åªæ›´æ–°å¿…è¦å­—æ®µ
                config_data["path"] = str(evreal_dir / "sequence")
                config_data["load_name"] = dataset_name
                print(f"å¤ç”¨ä¸€é”®å¼é…ç½®: {reference_config_file}")
            
            # åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶
            config_file = config_dir / f"{dataset_name}.json"
            
            with open(config_file, 'w') as f:
                json.dump(config_data, f, indent=2)
                
            print(f"âœ… åˆ›å»ºEVREALæ•°æ®é›†é…ç½®: {config_file}")
            
        except Exception as e:
            print(f"åˆ›å»ºEVREALé…ç½®å¤±è´¥: {e}")
    
    def copy_evreal_results(self, evreal_path: Path, output_dir: Path, dataset_name: str, methods: List[str]):
        """å¤åˆ¶EVREALé‡å»ºç»“æžœåˆ°è¾“å‡ºç›®å½•"""
        try:
            outputs_dir = evreal_path / "outputs"
            if not outputs_dir.exists():
                print(f"è­¦å‘Š: EVREALè¾“å‡ºç›®å½•ä¸å­˜åœ¨ {outputs_dir}")
                return
            
            # æŸ¥æ‰¾é‡å»ºç»“æžœ
            for method in methods:
                method_pattern = f"*{dataset_name}*{method}*"
                method_dirs = list(outputs_dir.glob(method_pattern))
                
                if method_dirs:
                    source_dir = method_dirs[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç›®å½•
                    target_dir = output_dir / f"evreal_{method.lower()}"
                    
                    if source_dir.exists():
                        # å¤åˆ¶é‡å»ºå›¾åƒ
                        target_dir.mkdir(parents=True, exist_ok=True)
                        for png_file in source_dir.glob("*.png"):
                            shutil.copy2(png_file, target_dir / png_file.name)
                        
                        png_count = len(list(target_dir.glob("*.png")))
                        print(f"    ðŸ“ {method}: å¤åˆ¶äº†{png_count}å¼ é‡å»ºå›¾åƒåˆ° {target_dir}")
                else:
                    print(f"    âš ï¸  {method}: æœªæ‰¾åˆ°é‡å»ºç»“æžœ")
                    
        except Exception as e:
            print(f"å¤åˆ¶EVREALç»“æžœå¤±è´¥: {e}")
    
    def process_single_h5(self, h5_file: Path) -> bool:
        """å¤„ç†å•ä¸ªH5æ–‡ä»¶"""
        print(f"\n{'='*60}")
        print(f"ðŸš€ å¤„ç†H5æ–‡ä»¶: {h5_file.name}")
        print(f"{'='*60}")
        
        # 1. åŠ è½½H5æ•°æ®
        h5_events = self.load_h5_events(h5_file)
        if h5_events is None:
            return False
        
        # 2. ç”Ÿæˆè¾“å‡ºç›®å½•å
        recon_name = self.generate_reconstruction_name(h5_file)
        
        # 3. åˆ›å»ºä¸´æ—¶EVREALå·¥ä½œç›®å½•
        temp_evreal_dir = self.temp_dir / f"evreal_{h5_file.stem}"
        
        # 4. H5â†’EVREALæ ¼å¼è½¬æ¢
        print(f"æ­¥éª¤1: H5â†’EVREALæ ¼å¼è½¬æ¢")
        if not self.h5_to_evreal_format(h5_events, temp_evreal_dir):
            return False
            
        # 5. åˆ›å»ºé‡å»ºè¾“å‡ºç›®å½•
        output_dir = self.dataset_dir / recon_name
        
        # 6. è°ƒç”¨EVREALé‡å»º
        print(f"æ­¥éª¤2: EVREALé‡å»º")
        success = self.run_evreal_reconstruction(temp_evreal_dir, output_dir, h5_file.stem)
        
        # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_evreal_dir.exists():
            shutil.rmtree(temp_evreal_dir)
            print(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_evreal_dir}")
        
        return success
    
    def run_batch_reconstruction(self) -> Dict[str, bool]:
        """è¿è¡Œæ‰¹é‡é‡å»º"""
        print("ðŸŽ¯ H5äº‹ä»¶æ•°æ®æ‰¹é‡é‡å»º")
        print(f"H5ç›®å½•: {self.h5_dir}")
        print(f"æ•°æ®é›†ç›®å½•: {self.dataset_dir}")
        
        # æ‰«æH5æ–‡ä»¶
        h5_files = self.scan_h5_files()
        if not h5_files:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„H5æ–‡ä»¶")
            return {}
        
        # æ‰¹é‡å¤„ç†
        results = {}
        for i, h5_file in enumerate(h5_files):
            print(f"\nè¿›åº¦: [{i+1}/{len(h5_files)}]")
            success = self.process_single_h5(h5_file)
            results[h5_file.name] = success
        
        # æ€»ç»“ç»“æžœ
        print(f"\n{'='*60}")
        print("ðŸŽ‰ æ‰¹é‡é‡å»ºå®Œæˆ - æ€»ç»“")
        print(f"{'='*60}")
        
        success_count = sum(results.values())
        total_count = len(results)
        
        print(f"æ€»ä½“ç»“æžœ: {success_count}/{total_count} ä¸ªæ–‡ä»¶å¤„ç†æˆåŠŸ")
        
        for h5_name, success in results.items():
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
            print(f"  {h5_name}: {status}")
            
        return results

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    dataset_dir = Path("datasets/lego") 
    h5_dir = dataset_dir / "events_h5"
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not h5_dir.exists():
        print(f"é”™è¯¯: H5ç›®å½•ä¸å­˜åœ¨ {h5_dir}")
        print("è¯·å…ˆè¿è¡Œäº‹ä»¶æ•°æ®ç”Ÿæˆpipeline")
        return False
    
    # åˆ›å»ºæ‰¹é‡é‡å»ºå™¨
    reconstructor = H5BatchReconstructor(h5_dir, dataset_dir)
    
    # æ‰§è¡Œæ‰¹é‡é‡å»º
    results = reconstructor.run_batch_reconstruction()
    
    # è¿”å›žæ‰§è¡Œç»“æžœ
    return len(results) > 0 and all(results.values())

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)