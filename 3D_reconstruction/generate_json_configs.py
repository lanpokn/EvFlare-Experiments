#!/usr/bin/env python3
"""
ä¸ºä¸åŒé‡å»ºæ–¹æ³•å’ŒH5æ•°æ®æºç”Ÿæˆ3DGSè®­ç»ƒç”¨çš„JSONé…ç½®æ–‡ä»¶
æ”¯æŒ: reconstruction_original, reconstruction_Unet, reconstruction_Unetsimple
ç”¨æ³•: 
- python generate_json_configs.py lego2                      # ä¸ºæ‰€æœ‰æ–¹æ³•ç”ŸæˆJSON
- python generate_json_configs.py lego2 spade-e2vid          # åªä¸ºspade-e2vidæ–¹æ³•ç”ŸæˆJSON (ä¸‰ç§H5æ•°æ®æº)
"""

import json
import os
from pathlib import Path

def create_json_config(dataset_name, method_name, h5_type, images_subdir):
    """
    åˆ›å»ºå•ä¸ªé‡å»ºæ–¹æ³•çš„JSONé…ç½®æ–‡ä»¶
    
    Args:
        dataset_name: æ•°æ®é›†åç§° (å¦‚ lego2)
        method_name: é‡å»ºæ–¹æ³•å (å¦‚ spade-e2vid, firenet, original)
        h5_type: H5æ•°æ®æºç±»å‹ (original, Unet, Unetsimple)
        images_subdir: å›¾åƒå­ç›®å½•è·¯å¾„
    """
    dataset_dir = Path(f"datasets/{dataset_name}")
    
    # è¯»å–åŸå§‹çš„transforms_train.jsonä½œä¸ºæ¨¡æ¿
    template_path = dataset_dir / "transforms_train.json"
    if not template_path.exists():
        print(f"âŒ æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
        return None
    
    with open(template_path, 'r') as f:
        config = json.load(f)
    
    # æ£€æŸ¥å›¾åƒç›®å½•æ˜¯å¦å­˜åœ¨
    images_path = dataset_dir / images_subdir
    if not images_path.exists():
        print(f"âš ï¸  å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_path}")
        return None
    
    # æ›´æ–°æ‰€æœ‰frameçš„file_path
    for frame in config['frames']:
        old_path = frame['file_path']  # å¦‚ "train/0001"
        filename = Path(old_path).name  # æå– "0001"
        
        # è®¾ç½®æ–°çš„è·¯å¾„
        new_path = f"{images_subdir}/{filename}"
        frame['file_path'] = new_path
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶å
    if method_name == "original":
        output_filename = f"transforms_train_{method_name}.json"
    else:
        output_filename = f"transforms_train_{method_name}_{h5_type}.json"
    
    output_path = dataset_dir / output_filename
    
    with open(output_path, 'w') as f:
        json.dump(config, f, indent=4)
    
    print(f"âœ… å·²ç”Ÿæˆ: {output_filename}")
    return output_path

def get_available_h5_sources(dataset_name):
    """è·å–å¯ç”¨çš„H5æ•°æ®æºåˆ—è¡¨"""
    dataset_dir = Path(f"datasets/{dataset_name}")
    h5_sources = []
    
    # æ‰«ææ‰€æœ‰reconstruction_*ç›®å½•
    for item in dataset_dir.iterdir():
        if item.is_dir() and item.name.startswith('reconstruction'):
            if item.name == 'reconstruction':
                continue  # è·³è¿‡æ—§çš„reconstructionç›®å½•
            
            # æå–H5ç±»å‹
            if item.name == 'reconstruction_original':
                h5_type = 'original'
            else:
                h5_type = item.name.replace('reconstruction_', '')
            
            h5_sources.append((h5_type, item.name))
    
    return h5_sources

def get_available_methods(dataset_name, h5_sources):
    """è·å–æ‰€æœ‰H5æ•°æ®æºä¸­çš„å¯ç”¨é‡å»ºæ–¹æ³•"""
    dataset_dir = Path(f"datasets/{dataset_name}")
    all_methods = set()
    
    # æ‰«ææ¯ä¸ªH5æ•°æ®æºç›®å½•æ‰¾åˆ°é€šç”¨æ–¹æ³•
    for h5_type, h5_dir_name in h5_sources:
        h5_dir = dataset_dir / h5_dir_name
        if not h5_dir.exists():
            continue
            
        for method_dir in h5_dir.iterdir():
            if method_dir.is_dir() and method_dir.name.startswith('evreal_'):
                method_name = method_dir.name.replace('evreal_', '').replace('-', '_')
                all_methods.add(method_name)
    
    return sorted(list(all_methods))

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        dataset_name = sys.argv[1]
    else:
        dataset_name = "lego2"
    
    # æ”¯æŒæŒ‡å®šå•ä¸ªæ–¹æ³•
    if len(sys.argv) > 2:
        target_method = sys.argv[2].replace('-', '_')  # ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿
    else:
        target_method = None
    
    dataset_dir = Path(f"datasets/{dataset_name}")
    if not dataset_dir.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        return
    
    print(f"ğŸš€ ä¸ºæ•°æ®é›† {dataset_name} ç”ŸæˆJSONé…ç½®æ–‡ä»¶...")
    if target_method:
        print(f"ğŸ¯ æŒ‡å®šé‡å»ºæ–¹æ³•: {target_method}")
    
    # 1. è·å–æ‰€æœ‰H5æ•°æ®æº
    h5_sources = get_available_h5_sources(dataset_name)
    if not h5_sources:
        print(f"âš ï¸  æœªæ‰¾åˆ°H5é‡å»ºæ•°æ®æºç›®å½•")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(h5_sources)} ä¸ªH5æ•°æ®æº: {[h5_type for h5_type, _ in h5_sources]}")
    
    # 2. è·å–æ‰€æœ‰å¯ç”¨æ–¹æ³•
    available_methods = get_available_methods(dataset_name, h5_sources)
    if not available_methods:
        print(f"âš ï¸  æœªæ‰¾åˆ°å¯ç”¨çš„é‡å»ºæ–¹æ³•")
        return
    
    print(f"ğŸ”§ æ‰¾åˆ° {len(available_methods)} ä¸ªé‡å»ºæ–¹æ³•: {available_methods}")
    
    # 3. ç”ŸæˆåŸå§‹è®­ç»ƒæ•°æ®çš„é…ç½® (åªç”Ÿæˆä¸€æ¬¡)
    generated_configs = []
    
    if (dataset_dir / "train").exists():
        config_path = create_json_config(dataset_name, "original", "original", "train")
        if config_path:
            generated_configs.append(("original", "original"))
    
    # 4. ä¸ºæ¯ä¸ªæŒ‡å®šæ–¹æ³•çš„æ¯ä¸ªH5æ•°æ®æºç”Ÿæˆé…ç½®
    for method_name in available_methods:
        # å¦‚æœæŒ‡å®šäº†ç‰¹å®šæ–¹æ³•ï¼Œåªå¤„ç†è¯¥æ–¹æ³•
        if target_method and target_method != method_name:
            continue
        
        for h5_type, h5_dir_name in h5_sources:
            # æ„å»ºå›¾åƒè·¯å¾„
            evreal_method_name = method_name.replace('_', '-')
            images_subdir = f"{h5_dir_name}/evreal_{evreal_method_name}"
            
            # æ£€æŸ¥æ–¹æ³•ç›®å½•æ˜¯å¦å­˜åœ¨
            method_path = dataset_dir / images_subdir
            if not method_path.exists():
                print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„æ–¹æ³•: {images_subdir}")
                continue
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config_path = create_json_config(
                dataset_name,
                method_name,
                h5_type,
                images_subdir
            )
            
            if config_path:
                config_key = f"{method_name}_{h5_type}"
                generated_configs.append((config_key, h5_type))
    
    if not generated_configs:
        print(f"âš ï¸  æ²¡æœ‰ç”Ÿæˆä»»ä½•é…ç½®æ–‡ä»¶")
        return
    
    print(f"\nğŸ‰ é…ç½®ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(generated_configs)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # 5. ç”Ÿæˆè®­ç»ƒé…ç½®ç»„åˆåˆ—è¡¨
    print(f"\nğŸ“‹ ç”Ÿæˆçš„è®­ç»ƒé…ç½®:")
    print(f"1. åŸå§‹è®­ç»ƒ: transforms_train_original.json")
    
    # æŒ‰æ–¹æ³•åˆ†ç»„æ˜¾ç¤º
    if target_method:
        print(f"2. {target_method} æ–¹æ³•çš„ä¸‰ç§H5æ•°æ®æº:")
        for config_key, h5_type in generated_configs:
            if config_key.startswith(target_method) and h5_type != 'original':
                print(f"   - transforms_train_{config_key}.json ({h5_type})")
    else:
        method_groups = {}
        for config_key, h5_type in generated_configs:
            if h5_type != 'original':
                method = config_key.split('_')[0] + '_' + config_key.split('_')[1] if '_' in config_key.split('_', 1)[1] else config_key.split('_')[0]
                if method not in method_groups:
                    method_groups[method] = []
                method_groups[method].append((config_key, h5_type))
        
        for i, (method, configs) in enumerate(method_groups.items(), 2):
            print(f"{i}. {method} æ–¹æ³•:")
            for config_key, h5_type in configs:
                print(f"   - transforms_train_{config_key}.json ({h5_type})")
    
    # 6. ç”ŸæˆWindowsæ‰¹å¤„ç†è„šæœ¬å¯ç”¨çš„æ–¹æ³•åˆ—è¡¨
    if target_method:
        # å¦‚æœæŒ‡å®šäº†æ–¹æ³•ï¼Œç”Ÿæˆè¯¥æ–¹æ³•çš„H5æ•°æ®æºåˆ—è¡¨
        training_combinations = ["original"]  # æ€»æ˜¯åŒ…å«åŸå§‹è®­ç»ƒ
        for config_key, h5_type in generated_configs:
            if config_key.startswith(target_method):
                training_combinations.append(config_key)
        
        methods_file = dataset_dir / f"training_methods_{target_method}.txt"
        with open(methods_file, 'w') as f:
            for combo in training_combinations:
                f.write(f"{combo}\n")
        
        print(f"\nğŸ“ å·²ç”Ÿæˆæ–¹æ³•åˆ—è¡¨: training_methods_{target_method}.txt")
        print(f"ğŸ¯ {target_method} è®­ç»ƒç»„åˆ: {training_combinations}")
    else:
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼:")
        print(f"   æŒ‡å®šæ–¹æ³•é‡æ–°ç”Ÿæˆ: python generate_json_configs.py {dataset_name} spade-e2vid")
        print(f"   ç„¶åè¿è¡Œæ‰¹å¤„ç†: auto_train_3dgs.bat {dataset_name} spade_e2vid")

if __name__ == "__main__":
    main()