#!/usr/bin/env python3
"""
è¯¦ç»†çš„H5æ–‡ä»¶å¯¹æ¯”åˆ†æ
å¯¹æ¯”ä¿®å¤å‰åçš„æ•°æ®ï¼Œå¹¶ä¸åŸå§‹DVSæ•°æ®éªŒè¯
"""

import h5py
import numpy as np
import os

def load_dvs_reference():
    """åŠ è½½åŸå§‹DVSæ•°æ®ä½œä¸ºå‚è€ƒ"""
    dvs_file = "/mnt/e/2025/event_flick_flare/experiments/3D_reconstruction/datasets/lego/events_dvs/lego_train_events.txt"
    
    if not os.path.exists(dvs_file):
        print(f"âŒ åŸå§‹DVSæ–‡ä»¶ä¸å­˜åœ¨: {dvs_file}")
        return None
        
    print(f"ğŸ“– åŠ è½½åŸå§‹DVSæ•°æ®: {dvs_file}")
    try:
        # DVSæ ¼å¼: timestamp_us, x, y, polarity
        data = np.loadtxt(dvs_file, delimiter=' ')
        print(f"  åŠ è½½æˆåŠŸ: {len(data):,} ä¸ªäº‹ä»¶")
        return {
            't': data[:, 0],  # timestamp_us
            'x': data[:, 1],  # x
            'y': data[:, 2],  # y  
            'p': data[:, 3]   # polarity
        }
    except Exception as e:
        print(f"âŒ åŠ è½½DVSæ–‡ä»¶å¤±è´¥: {e}")
        return None

def analyze_h5_file(filepath, label):
    """è¯¦ç»†åˆ†æH5æ–‡ä»¶"""
    print(f"\n{'='*60}")
    print(f"åˆ†æ {label}")
    print(f"æ–‡ä»¶: {filepath}")
    print(f"{'='*60}")
    
    if not os.path.exists(filepath):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return None
        
    try:
        with h5py.File(filepath, 'r') as f:
            events = f['events']
            data = {}
            
            print(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
            print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(filepath) / (1024*1024):.2f} MB")
            
            for field in ['t', 'x', 'y', 'p']:
                if field in events:
                    field_data = events[field][:]
                    data[field] = field_data
                    
                    print(f"\n{field}å­—æ®µ:")
                    print(f"  æ•°æ®é‡: {len(field_data):,}")
                    print(f"  æ•°æ®ç±»å‹: {field_data.dtype}")
                    print(f"  èŒƒå›´: [{field_data.min()}, {field_data.max()}]")
                    print(f"  å‰5ä¸ªå€¼: {field_data[:5]}")
                    print(f"  å5ä¸ªå€¼: {field_data[-5:]}")
                    
                    # æ•°æ®åˆ†å¸ƒç»Ÿè®¡
                    if field in ['x', 'y']:
                        unique_count = len(np.unique(field_data))
                        print(f"  å”¯ä¸€å€¼æ•°é‡: {unique_count}")
                    elif field == 'p':
                        unique_values, counts = np.unique(field_data, return_counts=True)
                        print(f"  ææ€§åˆ†å¸ƒ: {dict(zip(unique_values, counts))}")
                        
            return data
            
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return None

def compare_datasets(data1, data2, label1, label2):
    """å¯¹æ¯”ä¸¤ä¸ªæ•°æ®é›†"""
    print(f"\n{'ğŸ” æ•°æ®é›†å¯¹æ¯”'}")
    print(f"{label1} vs {label2}")
    print(f"{'='*60}")
    
    if data1 is None or data2 is None:
        print("âŒ æ— æ³•å¯¹æ¯”ï¼Œå­˜åœ¨ç©ºæ•°æ®é›†")
        return
        
    for field in ['t', 'x', 'y', 'p']:
        if field in data1 and field in data2:
            d1, d2 = data1[field], data2[field]
            
            print(f"\n{field}å­—æ®µå¯¹æ¯”:")
            print(f"  {label1}: èŒƒå›´[{d1.min()}, {d1.max()}], æ•°é‡{len(d1):,}")
            print(f"  {label2}: èŒƒå›´[{d2.min()}, {d2.max()}], æ•°é‡{len(d2):,}")
            
            if len(d1) == len(d2):
                # æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œå…¨ç›¸åŒ
                if np.array_equal(d1, d2):
                    print(f"  âœ… æ•°æ®å®Œå…¨ç›¸åŒ")
                else:
                    diff_count = np.sum(d1 != d2)
                    print(f"  âŒ æ•°æ®ä¸åŒ: {diff_count:,} ä¸ªä½ç½®ä¸åŒ")
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªä¸åŒçš„ä½ç½®
                    diff_indices = np.where(d1 != d2)[0][:5]
                    for idx in diff_indices:
                        print(f"    ä½ç½®{idx}: {d1[idx]} vs {d2[idx]}")
            else:
                print(f"  âŒ æ•°æ®é•¿åº¦ä¸åŒ")

def main():
    """ä¸»å‡½æ•°"""
    print(f"ğŸ” H5æ–‡ä»¶ä¿®å¤å‰åè¯¦ç»†å¯¹æ¯”åˆ†æ")
    
    # æ–‡ä»¶è·¯å¾„
    current_file = "/mnt/e/2025/event_flick_flare/experiments/3D_reconstruction/datasets/lego/events_h5/lego_sequence.h5"
    backup_file = "/mnt/e/2025/event_flick_flare/experiments/3D_reconstruction/datasets/lego/events_h5/lego_sequence_backup_wrong.h5"
    
    # åŠ è½½åŸå§‹DVSæ•°æ®ä½œä¸ºåŸºå‡†
    dvs_data = load_dvs_reference()
    
    # åˆ†æä¿®å¤åçš„æ–‡ä»¶
    current_data = analyze_h5_file(current_file, "ä¿®å¤åçš„H5æ–‡ä»¶")
    
    # åˆ†æä¿®å¤å‰çš„æ–‡ä»¶
    backup_data = analyze_h5_file(backup_file, "ä¿®å¤å‰çš„H5æ–‡ä»¶ï¼ˆé”™è¯¯ç‰ˆæœ¬ï¼‰")
    
    # å¯¹æ¯”ä¿®å¤å‰å
    if current_data and backup_data:
        compare_datasets(current_data, backup_data, "ä¿®å¤å", "ä¿®å¤å‰")
    
    # éªŒè¯ä¿®å¤åçš„æ•°æ®ä¸åŸå§‹DVSæ•°æ®æ˜¯å¦åŒ¹é…
    if current_data and dvs_data:
        print(f"\nğŸ¯ ä¿®å¤åH5æ•°æ® vs åŸå§‹DVSæ•°æ®éªŒè¯")
        print(f"{'='*60}")
        
        for field in ['t', 'x', 'y', 'p']:
            h5_data = current_data[field]
            dvs_ref = dvs_data[field]
            
            print(f"\n{field}å­—æ®µéªŒè¯:")
            print(f"  H5æ•°æ®: èŒƒå›´[{h5_data.min()}, {h5_data.max()}], æ•°é‡{len(h5_data):,}")
            print(f"  DVSåŸå§‹: èŒƒå›´[{dvs_ref.min()}, {dvs_ref.max()}], æ•°é‡{len(dvs_ref):,}")
            
            if len(h5_data) == len(dvs_ref):
                if np.allclose(h5_data, dvs_ref):
                    print(f"  âœ… ä¸åŸå§‹DVSæ•°æ®å®Œå…¨åŒ¹é…")
                else:
                    diff_count = np.sum(~np.isclose(h5_data, dvs_ref))
                    print(f"  âŒ ä¸åŸå§‹æ•°æ®ä¸åŒ¹é…: {diff_count:,} ä¸ªå·®å¼‚")
            else:
                print(f"  âŒ æ•°æ®é•¿åº¦ä¸åŒ¹é…")
    
    print(f"\n{'ğŸ“‹ éªŒè¯æ€»ç»“'}")
    print(f"{'='*60}")
    if current_data:
        # éªŒè¯æ•°æ®èŒƒå›´
        ranges_ok = (
            225 <= current_data['t'].min() <= current_data['t'].max() <= 199000 and
            20 <= current_data['x'].min() <= current_data['x'].max() <= 639 and
            0 <= current_data['y'].min() <= current_data['y'].max() <= 479 and
            set(np.unique(current_data['p'])) == {0.0, 1.0}
        )
        
        print(f"ä¿®å¤åH5æ–‡ä»¶æ•°æ®èŒƒå›´éªŒè¯: {'âœ… é€šè¿‡' if ranges_ok else 'âŒ å¤±è´¥'}")
        print(f"æ•°æ®é‡: {len(current_data['t']):,} ä¸ªäº‹ä»¶")
        print(f"æ—¶é—´èŒƒå›´: {current_data['t'].min():.0f} - {current_data['t'].max():.0f} Î¼s")
        print(f"ç©ºé—´èŒƒå›´: X[{current_data['x'].min():.0f}, {current_data['x'].max():.0f}], Y[{current_data['y'].min():.0f}, {current_data['y'].max():.0f}]")
        
        # ææ€§åˆ†å¸ƒ
        unique_p, counts_p = np.unique(current_data['p'], return_counts=True)
        p_dist = dict(zip(unique_p, counts_p))
        print(f"ææ€§åˆ†å¸ƒ: ON={p_dist.get(1.0, 0):,}, OFF={p_dist.get(0.0, 0):,}")

if __name__ == "__main__":
    main()