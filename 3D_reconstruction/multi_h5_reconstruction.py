#!/usr/bin/env python3
"""
é€šç”¨å¤šH5æ–‡ä»¶é‡å»ºè„šæœ¬
æ”¯æŒå¯¹ä»»æ„æ•°æ®é›†ä¸­çš„å¤šä¸ªH5æ–‡ä»¶è¿›è¡ŒEVREALé‡å»º
æ¯ä¸ªH5æ–‡ä»¶ç”Ÿæˆç‹¬ç«‹çš„é‡å»ºç›®å½•

ä½¿ç”¨æ–¹æ³•:
source ~/miniconda3/etc/profile.d/conda.sh && conda activate Umain2 && python multi_h5_reconstruction.py [dataset_name]

ç¤ºä¾‹:
python multi_h5_reconstruction.py lego2
python multi_h5_reconstruction.py ship  

Author: Claude Code Assistant
Date: 2025-09-25
"""

import os
import sys
import h5py
import shutil
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
sys.path.append('..')

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from pipeline_architecture import DataFormat, FormatConverter
    from modules.format_converter import ConversionConfig, DVSToEVREALConverter
    from modules.evreal_integration import EVREALIntegrationConfig, EVREALIntegration
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)

class MultiH5ReconstructionManager:
    """é€šç”¨å¤šH5æ–‡ä»¶é‡å»ºç®¡ç†å™¨"""
    
    def __init__(self, dataset_name: str):
        self.dataset_name = dataset_name
        self.dataset_dir = Path("datasets") / dataset_name
        self.h5_dir = self.dataset_dir / "events_h5"
        self.original_evreal_dir = self.dataset_dir / "events_evreal"
        
        # éªŒè¯å¿…è¦ç›®å½•å­˜åœ¨
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.dataset_dir}")
        if not self.h5_dir.exists():
            raise FileNotFoundError(f"H5ç›®å½•ä¸å­˜åœ¨: {self.h5_dir}")
        if not self.original_evreal_dir.exists():
            raise FileNotFoundError(f"åŸå§‹EVREALç›®å½•ä¸å­˜åœ¨: {self.original_evreal_dir}")
    
    def get_h5_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„H5æ–‡ä»¶"""
        h5_files = []
        for h5_file in self.h5_dir.glob("*.h5"):
            # è·³è¿‡å¤‡ä»½æ–‡ä»¶
            if "backup" in h5_file.name or "wrong" in h5_file.name:
                continue
            h5_files.append(h5_file)
        
        h5_files.sort()  # æŒ‰åç§°æ’åº
        print(f"æ‰¾åˆ° {len(h5_files)} ä¸ªH5æ–‡ä»¶å¾…å¤„ç†:")
        for h5_file in h5_files:
            print(f"  - {h5_file.name}")
        return h5_files
    
    def get_suffix_from_filename(self, h5_file: Path) -> str:
        """ä»H5æ–‡ä»¶åæå–åç¼€ï¼Œæ”¯æŒå¤šç§å‘½åæ¨¡å¼"""
        stem = h5_file.stem  # å»æ‰.h5æ‰©å±•å
        
        # å°è¯•å¤šç§å‘½åæ¨¡å¼
        base_patterns = [
            f"{self.dataset_name}_sequence_new",
            f"{self.dataset_name}_sequence", 
            f"{self.dataset_name}_train_events",
            f"{self.dataset_name}"
        ]
        
        for base_pattern in base_patterns:
            if stem.startswith(base_pattern):
                suffix = stem.replace(base_pattern, "")
                if suffix.startswith("_"):
                    return suffix[1:]  # ç§»é™¤å‰å¯¼ä¸‹åˆ’çº¿
                elif suffix == "":
                    return "original"  # åŸå§‹æ–‡ä»¶
                else:
                    return suffix
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´æ–‡ä»¶åä½œä¸ºåç¼€
        return stem.replace(".", "_")
    
    def h5_to_evreal_conversion(self, h5_file: Path, suffix: str) -> Path:
        """å°†H5æ–‡ä»¶è½¬æ¢ä¸ºEVREALæ ¼å¼"""
        print(f"\n=== è½¬æ¢H5æ–‡ä»¶: {h5_file.name} (åç¼€: {suffix}) ===")
        
        # åˆ›å»ºä¸´æ—¶EVREALç›®å½•
        temp_evreal_dir = self.dataset_dir / f"events_evreal_{suffix}"
        sequence_dir = temp_evreal_dir / "sequence"
        sequence_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # è¯»å–H5æ–‡ä»¶
            print(f"è¯»å–H5æ–‡ä»¶: {h5_file}")
            with h5py.File(h5_file, 'r') as f:
                # æ£€æŸ¥H5æ–‡ä»¶ç»“æ„
                if 'events' in f and isinstance(f['events'], h5py.Group):
                    # æ ¼å¼: events/t, events/x, events/y, events/p
                    events_t = f['events/t'][:]
                    events_x = f['events/x'][:]
                    events_y = f['events/y'][:]
                    events_p = f['events/p'][:]
                    print(f"H5äº‹ä»¶æ•°é‡: {len(events_t)} (åˆ†ç»„æ ¼å¼)")
                elif 'events' in f and isinstance(f['events'], h5py.Dataset):
                    # æ ¼å¼: events[:, [t,x,y,p]]
                    events_data = f['events'][:]
                    events_t = events_data[:, 0]
                    events_x = events_data[:, 1] 
                    events_y = events_data[:, 2]
                    events_p = events_data[:, 3]
                    print(f"H5äº‹ä»¶æ•°é‡: {len(events_data)} (æ•°ç»„æ ¼å¼)")
                else:
                    raise ValueError("æœªè¯†åˆ«çš„H5æ–‡ä»¶æ ¼å¼")
                
                # è½¬æ¢ä¸ºEVREALæ ¼å¼
                events_ts = events_t.astype(np.float64) / 1000000.0  # å¾®ç§’è½¬ç§’
                events_xy = np.column_stack([events_x.astype(np.int16), events_y.astype(np.int16)])  # [x, y]
                events_p = events_p.astype(np.int8)  # polarity
                
                # ä¿å­˜EVREALäº‹ä»¶æ–‡ä»¶
                np.save(sequence_dir / "events_ts.npy", events_ts)
                np.save(sequence_dir / "events_xy.npy", events_xy)
                np.save(sequence_dir / "events_p.npy", events_p)
                
                print(f"è½¬æ¢å®Œæˆ:")
                print(f"  - æ—¶é—´èŒƒå›´: {events_ts.min():.6f}s - {events_ts.max():.6f}s")
                print(f"  - ç©ºé—´èŒƒå›´: X[{events_xy[:, 0].min()}, {events_xy[:, 0].max()}], Y[{events_xy[:, 1].min()}, {events_xy[:, 1].max()}]")
                print(f"  - ææ€§åˆ†å¸ƒ: +{(events_p == 1).sum()}, -{(events_p == 0).sum()}")
            
            # å¤åˆ¶å›¾åƒç›¸å…³æ–‡ä»¶ï¼ˆä»åŸå§‹EVREALç›®å½•ï¼‰
            print("å¤åˆ¶å›¾åƒç›¸å…³æ–‡ä»¶...")
            original_sequence_dir = self.original_evreal_dir / "sequence"
            
            files_to_copy = [
                "images.npy",
                "images_ts.npy", 
                "image_event_indices.npy",
                "metadata.json"
            ]
            
            for file_name in files_to_copy:
                src_file = original_sequence_dir / file_name
                dst_file = sequence_dir / file_name
                if src_file.exists():
                    shutil.copy2(src_file, dst_file)
                    print(f"  âœ“ {file_name}")
                else:
                    print(f"  âš  æœªæ‰¾åˆ°: {file_name}")
            
            # å¤åˆ¶imagesç›®å½•
            src_images_dir = original_sequence_dir / "images"
            dst_images_dir = sequence_dir / "images"
            if src_images_dir.exists():
                if dst_images_dir.exists():
                    shutil.rmtree(dst_images_dir)
                shutil.copytree(src_images_dir, dst_images_dir)
                print(f"  âœ“ images/ ç›®å½• ({len(list(dst_images_dir.glob('*.png')))} å¼ å›¾åƒ)")
            
            # æ›´æ–°å…ƒæ•°æ®
            metadata_file = sequence_dir / "metadata.json"
            if metadata_file.exists():
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                
                # æ›´æ–°äº‹ä»¶ç›¸å…³ä¿¡æ¯
                metadata["num_events"] = len(events_ts)
                metadata["time_range_s"] = [float(events_ts.min()), float(events_ts.max())]
                metadata["spatial_range"] = {
                    "x_range": [int(events_xy[:, 0].min()), int(events_xy[:, 0].max())],
                    "y_range": [int(events_xy[:, 1].min()), int(events_xy[:, 1].max())]
                }
                metadata["source_h5_file"] = str(h5_file)
                metadata["conversion_suffix"] = suffix
                metadata["conversion_timestamp"] = time.strftime("%Y-%m-%dT%H:%M:%S")
                
                with open(metadata_file, 'w') as f:
                    json.dump(metadata, f, indent=2)
                print(f"  âœ“ æ›´æ–°metadata.json")
            
            print(f"âœ… H5â†’EVREALè½¬æ¢å®Œæˆ: {temp_evreal_dir}")
            return temp_evreal_dir
            
        except Exception as e:
            print(f"âŒ H5â†’EVREALè½¬æ¢å¤±è´¥: {e}")
            if temp_evreal_dir.exists():
                shutil.rmtree(temp_evreal_dir)
            raise e
    
    def run_evreal_reconstruction(self, evreal_dir: Path, suffix: str) -> Path:
        """è¿è¡ŒEVREALé‡å»º"""
        print(f"\n=== EVREALé‡å»º: {suffix} ===")
        
        try:
            # é…ç½®EVREALé›†æˆ
            config = EVREALIntegrationConfig()
            config.dataset_name = f"{self.dataset_name}_{suffix}"
            config.dataset_dir = self.dataset_dir
            config.evreal_data_dir = evreal_dir  # ä½¿ç”¨ä¸´æ—¶EVREALç›®å½•
            config.reconstruction_dir = self.dataset_dir / f"reconstruction_{suffix}"
            
            # è¿è¡Œé‡å»º
            integration = EVREALIntegration(config)
            result = integration.run_full_pipeline()
            
            if result.get("successful_methods"):
                print(f"âœ… é‡å»ºæˆåŠŸ: {result['successful_methods']}")
                print(f"   è¾“å‡ºç›®å½•: {config.output_base_dir}")
                return config.output_base_dir
            else:
                print(f"âŒ é‡å»ºå¤±è´¥: æ²¡æœ‰æˆåŠŸçš„æ–¹æ³•")
                return None
                
        except Exception as e:
            print(f"âŒ EVREALé‡å»ºå¤±è´¥: {e}")
            return None
    
    def cleanup_temp_evreal(self, temp_evreal_dir: Path):
        """æ¸…ç†ä¸´æ—¶EVREALç›®å½•"""
        try:
            if temp_evreal_dir.exists():
                shutil.rmtree(temp_evreal_dir)
                print(f"âœ“ æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_evreal_dir}")
        except Exception as e:
            print(f"âš  æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    
    def process_all_h5_files(self):
        """å¤„ç†æ‰€æœ‰H5æ–‡ä»¶"""
        h5_files = self.get_h5_files()
        if not h5_files:
            print("âŒ æœªæ‰¾åˆ°å¯å¤„ç†çš„H5æ–‡ä»¶")
            return
        
        print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(h5_files)} ä¸ªH5æ–‡ä»¶...")
        
        results = []
        for i, h5_file in enumerate(h5_files, 1):
            print(f"\n{'='*60}")
            print(f"å¤„ç†è¿›åº¦: {i}/{len(h5_files)} - {h5_file.name}")
            print(f"{'='*60}")
            
            suffix = self.get_suffix_from_filename(h5_file)
            temp_evreal_dir = None
            
            try:
                # H5â†’EVREALè½¬æ¢
                temp_evreal_dir = self.h5_to_evreal_conversion(h5_file, suffix)
                
                # EVREALé‡å»º
                reconstruction_dir = self.run_evreal_reconstruction(temp_evreal_dir, suffix)
                
                results.append({
                    "h5_file": h5_file.name,
                    "suffix": suffix,
                    "reconstruction_dir": reconstruction_dir,
                    "success": reconstruction_dir is not None
                })
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {h5_file.name}, é”™è¯¯: {e}")
                results.append({
                    "h5_file": h5_file.name,
                    "suffix": suffix,
                    "reconstruction_dir": None,
                    "success": False,
                    "error": str(e)
                })
            
            finally:
                # æš‚æ—¶ä¸æ¸…ç†ä¸´æ—¶ç›®å½•ï¼Œç”¨äºè°ƒè¯•
                if temp_evreal_dir and False:  # ä¸´æ—¶ç¦ç”¨æ¸…ç†
                    self.cleanup_temp_evreal(temp_evreal_dir)
        
        # è¾“å‡ºæœ€ç»ˆç»“æœ
        self.print_final_results(results)
    
    def print_final_results(self, results: List[Dict]):
        """æ‰“å°æœ€ç»ˆå¤„ç†ç»“æœ"""
        print(f"\n{'='*60}")
        print("ğŸ‰ å¤„ç†å®Œæˆ! ç»“æœæ±‡æ€»:")
        print(f"{'='*60}")
        
        successful = [r for r in results if r["success"]]
        failed = [r for r in results if not r["success"]]
        
        print(f"âœ… æˆåŠŸ: {len(successful)}/{len(results)}")
        for result in successful:
            print(f"   {result['h5_file']} â†’ reconstruction_{result['suffix']}/")
        
        if failed:
            print(f"\nâŒ å¤±è´¥: {len(failed)}/{len(results)}")
            for result in failed:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                print(f"   {result['h5_file']}: {error_msg}")
        
        # è®¡ç®—è¾“å‡ºç»Ÿè®¡
        if successful:
            print(f"\nğŸ“Š é‡å»ºå›¾åƒç»Ÿè®¡:")
            for result in successful:
                if result["reconstruction_dir"] and Path(result["reconstruction_dir"]).exists():
                    reconstruction_dir = Path(result["reconstruction_dir"])
                    png_count = len(list(reconstruction_dir.rglob("*.png")))
                    methods = [d.name for d in reconstruction_dir.iterdir() if d.is_dir()]
                    print(f"   {result['suffix']}: {png_count} å¼ å›¾åƒ, {len(methods)} ç§æ–¹æ³•")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šæ•°æ®é›†åç§°")
        print("ä½¿ç”¨æ–¹æ³•: python multi_h5_reconstruction.py <dataset_name>")
        print("ç¤ºä¾‹: python multi_h5_reconstruction.py lego2")
        sys.exit(1)
    
    dataset_name = sys.argv[1]
    
    print(f"ğŸ”¥ {dataset_name} å¤šH5æ–‡ä»¶é‡å»ºè„šæœ¬")
    print("=" * 60)
    
    # æ£€æŸ¥condaç¯å¢ƒ
    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')
    print(f"å½“å‰condaç¯å¢ƒ: {conda_env}")
    if conda_env != 'Umain2':
        print("âš ï¸  è­¦å‘Š: æœªåœ¨Umain2ç¯å¢ƒä¸­è¿è¡Œ!")
        print("è¯·ä½¿ç”¨: source ~/miniconda3/etc/profile.d/conda.sh && conda activate Umain2")
    
    try:
        # åˆ›å»ºç®¡ç†å™¨å¹¶è¿è¡Œ
        manager = MultiH5ReconstructionManager(dataset_name)
        manager.process_all_h5_files()
        
    except Exception as e:
        print(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    
    print(f"\nğŸ¯ {dataset_name} è„šæœ¬æ‰§è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main()