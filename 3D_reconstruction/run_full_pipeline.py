#!/usr/bin/env python3
"""
å®Œæ•´äº‹ä»¶ç›¸æœºé‡å»ºPipeline - é€šç”¨ä¸€é”®å¼è¿è¡Œ
æ”¯æŒä»»æ„æ•°æ®é›†: lego, ship, hotdogç­‰
ä» xxx_flare + xxx_normalå¼€å§‹ï¼Œåˆ°EVREALé‡å»ºç»“æœç»“æŸ

Author: Claude Code Assistant
Date: 2025-09-25 (Updated for universal support)
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path

def run_step(step_name: str, command: str, check_success=None):
    """è¿è¡ŒPipelineæ­¥éª¤"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ æ­¥éª¤: {step_name}")
    print(f"{'='*60}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                               capture_output=True, text=True)
        
        # æ£€æŸ¥æˆåŠŸæ¡ä»¶
        if check_success and not check_success():
            print(f"âŒ {step_name} - æˆåŠŸæ¡ä»¶æœªæ»¡è¶³")
            return False
            
        print(f"âœ… {step_name} - å®Œæˆ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ {step_name} - å¤±è´¥")
        print(f"é”™è¯¯: {e}")
        print(f"stdout: {e.stdout}")
        print(f"stderr: {e.stderr}")
        return False

def check_datasets(dataset_name):
    """æ£€æŸ¥åŸå§‹æ•°æ®é›†æ˜¯å¦å­˜åœ¨"""
    flare_dir = Path(f"datasets/{dataset_name}_flare")
    normal_dir = Path(f"datasets/{dataset_name}_normal")
    merged_dir = Path(f"datasets/{dataset_name}")
    
    print(f"ğŸ” æ£€æŸ¥{dataset_name}æ•°æ®é›†...")
    
    # æ£€æŸ¥åŸå§‹æ•°æ®é›†
    flare_exists = flare_dir.exists()
    normal_exists = normal_dir.exists() 
    merged_exists = merged_dir.exists()
    
    print(f"  {dataset_name}_flare: {'å­˜åœ¨' if flare_exists else 'ç¼ºå¤±'}")
    print(f"  {dataset_name}_normal: {'å­˜åœ¨' if normal_exists else 'ç¼ºå¤±'}")
    print(f"  {dataset_name} (åˆå¹¶): {'å­˜åœ¨' if merged_exists else 'ç¼ºå¤±'}")
    
    if not flare_exists or not normal_exists:
        print(f"âŒ ç¼ºå°‘{dataset_name}åŸå§‹æ•°æ®é›†")
        return False
        
    if not merged_exists:
        print(f"âš ï¸  {dataset_name}åˆå¹¶æ•°æ®é›†ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆè¿è¡Œåˆå¹¶")
        return False
        
    # éªŒè¯åˆå¹¶æ•°æ®é›†å®Œæ•´æ€§
    train_dir = merged_dir / "train"
    test_dir = merged_dir / "test"
    
    if not train_dir.exists() or not test_dir.exists():
        print(f"âŒ {dataset_name}åˆå¹¶æ•°æ®é›†ç»“æ„ä¸å®Œæ•´")
        return False
        
    train_count = len(list(train_dir.glob("*.png")))
    test_count = len(list(test_dir.glob("*.png")))
    
    print(f"âœ… {dataset_name}æ•°æ®é›†æ£€æŸ¥é€šè¿‡:")
    print(f"  è®­ç»ƒå›¾åƒ: {train_count}å¼ ")
    print(f"  æµ‹è¯•å›¾åƒ: {test_count}å¼ ")
    
    return True

def create_dataset_pipeline_commands(dataset_name):
    """ä¸ºæŒ‡å®šæ•°æ®é›†åˆ›å»ºpipelineå‘½ä»¤"""
    return {
        'preprocess': f'python -c "import sys; sys.path.append(\\".\\"); from modules.image_preprocessor import *; from pathlib import Path; config = PreprocessConfig(); config.input_dir = Path(\\"datasets/{dataset_name}/train\\"); preprocessor = ImagePreprocessor(config); result = preprocessor.process(); print(f\\"å¤„ç†å®Œæˆ: {{len(result.image_paths) if result else 0}}å¼ å›¾åƒ\\")"',
        
        'dvs_simulate': f'python -c "import sys; sys.path.append(\\".\\"); from modules.dvs_simulator import *; from modules.image_preprocessor import *; from pathlib import Path; preprocess_config = PreprocessConfig(); preprocess_config.input_dir = Path(\\"datasets/{dataset_name}/train\\"); preprocessor = ImagePreprocessor(preprocess_config); image_sequence = preprocessor.process(); dvs_config = DVSSimulatorConfig(); dvs_config.output_dir = Path(\\"datasets/{dataset_name}/events_dvs\\"); simulator = DVSSimulatorWrapper(dvs_config); result = simulator.simulate(image_sequence); print(f\\"DVSä»¿çœŸå®Œæˆ: {{result.metadata[\'num_events\'] if result else 0}}ä¸ªäº‹ä»¶\\")"',
        
        'convert_format': f'python -c "import sys; sys.path.append(\\".\\"); from modules.format_converter import *; from pathlib import Path; config = ConversionConfig(); config.dataset_name = \\"{dataset_name}\\"; config.dataset_dir = Path(\\"datasets/{dataset_name}\\"); config.dvs_events_dir = Path(\\"datasets/{dataset_name}/events_dvs\\"); config.evreal_output_dir = Path(\\"datasets/{dataset_name}/events_evreal\\"); converter = FormatConverterPipeline(config); dvs_file = Path(\\"datasets/{dataset_name}/events_dvs/{dataset_name}_train_events_new.txt\\"); result = converter.convert_dvs_events(dvs_file, \\"{dataset_name}_sequence_new\\"); print(\\"æ ¼å¼è½¬æ¢å®Œæˆ\\")"',
        
        'evreal_reconstruct': f'python -c "import sys; sys.path.append(\\".\\"); from modules.evreal_integration import *; from pathlib import Path; config = EVREALIntegrationConfig(); config.dataset_name = \\"{dataset_name}\\"; config.dataset_dir = Path(\\"datasets/{dataset_name}\\"); config.evreal_data_dir = Path(\\"datasets/{dataset_name}/events_evreal\\"); config.output_dir = Path(\\"datasets/{dataset_name}/reconstruction\\"); integration = EVREALIntegration(config); result = integration.run_full_pipeline(); print(\\"EVREALé‡å»ºå®Œæˆ: \\", result[\\"success\\"])"'
    }

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´Pipeline"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='é€šç”¨äº‹ä»¶ç›¸æœºé‡å»ºPipeline')
    parser.add_argument('dataset', nargs='?', default='lego', help='æ•°æ®é›†åç§° (é»˜è®¤: lego)')
    parser.add_argument('--auto-merge', action='store_true', help='å¦‚æœåˆå¹¶æ•°æ®é›†ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨è¿è¡Œmerge_datasets.py')
    parser.add_argument('--skip-preprocess', action='store_true', help='è·³è¿‡å›¾åƒé¢„å¤„ç†æ­¥éª¤')
    parser.add_argument('--skip-dvs', action='store_true', help='è·³è¿‡DVSä»¿çœŸæ­¥éª¤') 
    parser.add_argument('--skip-convert', action='store_true', help='è·³è¿‡æ ¼å¼è½¬æ¢æ­¥éª¤')
    parser.add_argument('--skip-reconstruct', action='store_true', help='è·³è¿‡EVREALé‡å»ºæ­¥éª¤')
    
    args = parser.parse_args()
    dataset_name = args.dataset
    
    print("ğŸ¯ é€šç”¨äº‹ä»¶ç›¸æœºé‡å»ºPipeline")
    print(f"æ•°æ®é›†: {dataset_name}")
    print(f"ä» {dataset_name}_flare + {dataset_name}_normal â†’ DVSäº‹ä»¶ â†’ EVREALé‡å»º")
    
    # æ£€æŸ¥æ•°æ®é›†
    if not check_datasets(dataset_name):
        if args.auto_merge:
            print("ğŸ”„ è‡ªåŠ¨è¿è¡Œæ•°æ®é›†åˆå¹¶...")
            success = run_step(
                "æ•°æ®é›†åˆå¹¶",
                "python merge_datasets.py",
                lambda: Path(f"datasets/{dataset_name}").exists()
            )
            if not success:
                return False
                
            # é‡æ–°æ£€æŸ¥
            if not check_datasets(dataset_name):
                return False
        else:
            print("è¯·å…ˆè¿è¡Œ: python merge_datasets.py")
            return False
    
    # è·å–æ•°æ®é›†ä¸“ç”¨å‘½ä»¤
    commands = create_dataset_pipeline_commands(dataset_name)
    
    # æ­¥éª¤1: å›¾åƒé¢„å¤„ç†
    if not args.skip_preprocess:
        success = run_step(
            f"{dataset_name}å›¾åƒé¢„å¤„ç†",
            commands['preprocess'],
            lambda: Path("temp/dvs_input").exists() and 
                    len(list(Path("temp/dvs_input").glob("*.png"))) > 0
        )
        if not success:
            return False
    
    # æ­¥éª¤2: DVSäº‹ä»¶ä»¿çœŸ
    if not args.skip_dvs:
        success = run_step(
            f"{dataset_name} DVSäº‹ä»¶ä»¿çœŸ",
            commands['dvs_simulate'],
            lambda: Path(f"datasets/{dataset_name}/events_dvs").exists() and 
                    len(list(Path(f"datasets/{dataset_name}/events_dvs").glob("*.txt"))) > 0
        )
        if not success:
            return False
    
    # æ­¥éª¤3: æ ¼å¼è½¬æ¢
    if not args.skip_convert:
        success = run_step(
            f"{dataset_name}æ ¼å¼è½¬æ¢",
            commands['convert_format'],
            lambda: Path(f"datasets/{dataset_name}/events_evreal/sequence/events_ts.npy").exists()
        )
        if not success:
            return False
    
    # æ­¥éª¤4: EVREALé‡å»º
    if not args.skip_reconstruct:
        success = run_step(
            f"{dataset_name} EVREALå›¾åƒé‡å»º",
            commands['evreal_reconstruct'],
            lambda: Path(f"datasets/{dataset_name}/reconstruction").exists()
        )
        if not success:
            return False
    
    # æœ€ç»ˆæ£€æŸ¥
    print(f"\n{'='*60}")
    print(f"ğŸ‰ {dataset_name} Pipelineå®Œæˆ - æœ€ç»ˆæ£€æŸ¥")
    print(f"{'='*60}")
    
    # ç»Ÿè®¡ç»“æœ
    train_images = len(list(Path(f"datasets/{dataset_name}/train").glob("*.png")))
    test_images = len(list(Path(f"datasets/{dataset_name}/test").glob("*.png")))
    events_dir = Path(f"datasets/{dataset_name}/events_dvs")
    reconstruction_dir = Path(f"datasets/{dataset_name}/reconstruction")
    
    print(f"âœ… {dataset_name}è®­ç»ƒå›¾åƒ (flare): {train_images}å¼ ")
    print(f"âœ… {dataset_name}æµ‹è¯•å›¾åƒ (normal): {test_images}å¼ ")
    
    # æ£€æŸ¥äº‹ä»¶æ•°æ®
    if events_dir.exists():
        event_files = list(events_dir.glob("*.txt"))
        print(f"âœ… {dataset_name} DVSäº‹ä»¶æ•°æ®: {len(event_files)}ä¸ªæ–‡ä»¶")
        
        # ç»Ÿè®¡äº‹ä»¶æ•°é‡
        if event_files:
            try:
                import numpy as np
                events = np.loadtxt(event_files[0])
                print(f"   äº‹ä»¶æ€»æ•°: {len(events):,}ä¸ª")
            except:
                print(f"   (æ— æ³•è¯»å–äº‹ä»¶æ•°æ®)")
    else:
        print(f"âŒ {dataset_name} DVSäº‹ä»¶æ•°æ®: ç¼ºå¤±")
    
    # æ£€æŸ¥é‡å»ºç»“æœ
    if reconstruction_dir.exists():
        recon_methods = list(reconstruction_dir.glob("evreal_*"))
        print(f"âœ… {dataset_name}é‡å»ºæ–¹æ³•: {[m.name for m in recon_methods]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å»ºå›¾åƒ
        total_recon_images = 0
        for method_dir in recon_methods:
            png_count = len(list(method_dir.glob("*.png")))
            total_recon_images += png_count
            print(f"   {method_dir.name}: {png_count}å¼ é‡å»ºå›¾åƒ")
            
        print(f"âœ… {dataset_name}é‡å»ºå›¾åƒæ€»è®¡: {total_recon_images}å¼ ")
    else:
        print(f"âŒ {dataset_name}é‡å»ºç»“æœç›®å½•: ç¼ºå¤±")
    
    print(f"\nğŸ¯ {dataset_name} Pipelineæ‰§è¡Œå®Œæ¯•!")
    print(f"æ€»ä½“çŠ¶æ€: å®Œå…¨æˆåŠŸ")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)